{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the entropy function\n",
    "\n",
    "def entropy(y):\n",
    "    N= len(y)\n",
    "    s= (y==1).sum()\n",
    "    if s==0 or N==s:\n",
    "        return 0\n",
    "    p1=float(s/N)\n",
    "    p0=1-p1 \n",
    "    ent = -p1*np.log2(p1) -p0*np.log2(p0)\n",
    "    return ent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the dat from train\n",
    "def get_data():\n",
    "    df= pd.read_csv('/Users/sunpreet/Downloads/train.csv')\n",
    "    data =df.as_matrix()\n",
    "    np.random.shuffle(data)\n",
    "    X=data[:,1:]/255\n",
    "    Y=data[:,0]\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a decision tree class\n",
    "\n",
    "class TreeNode:\n",
    "    \n",
    "    def __init__(self,current_depth=0,max_depth=None):\n",
    "        self.current_depth = current_depth\n",
    "        self.max_depth= max_depth\n",
    "        \n",
    "        \n",
    "                    \n",
    "    def fit(self,X,Y):  \n",
    "        \n",
    "        if len(Y)== 1 or len(set(Y)) == 1:\n",
    "            self.col = None\n",
    "            self.split = None\n",
    "            self.left = None\n",
    "            self.right = None\n",
    "            self.prediction = Y[0]\n",
    "        else:\n",
    "            D=X.shape[1]\n",
    "            cols = range(D)\n",
    "            max_ig = 0\n",
    "            best_split= None\n",
    "            best_col=None\n",
    "            for col in cols:\n",
    "                ig,split = self.find_split(X,Y,col)\n",
    "                if ig > max_ig:\n",
    "                    max_ig = ig\n",
    "                    best_split= split\n",
    "                    best_col = col\n",
    "                    \n",
    "            if max_ig == 0:\n",
    "                self.col = None\n",
    "                self.split = None\n",
    "                self.left = None\n",
    "                self.right = None\n",
    "                self.prediction = np.round(Y.mean())\n",
    "            else:\n",
    "                self.col=best_col\n",
    "                self.split=best_split\n",
    "                \n",
    "                if self.current_depth==self.max_depth:\n",
    "                    self.left = None\n",
    "                    self.right = None\n",
    "                    self.prediction = [\n",
    "                        np.round(Y[X[:,best_col] < self.split].mean()),\n",
    "                        np.round(Y[X[:,best_col] >= self.split].mean()),\n",
    "                    ]\n",
    "\n",
    "                else:\n",
    "                    left_idx = (X[:,best_col] < best_split)\n",
    "                    Xleft = X[left_idx]\n",
    "                    Yleft = Y[left_idx]\n",
    "                    self.left = TreeNode(self.current_depth + 1,self.max_depth)\n",
    "                    self.left.fit(Xleft,Yleft)\n",
    "                    \n",
    "                    right_idx = (X[:,best_col] >= best_split)\n",
    "                    Xright = X[right_idx]\n",
    "                    Yright = Y[right_idx]\n",
    "                    self.right = TreeNode(self.current_depth + 1,self.max_depth)\n",
    "                    self.right.fit(Xright,Yright) \n",
    "    \n",
    "    def find_split(self,X,Y,col):\n",
    "            x_values=X[:,col]\n",
    "            sort_indx = np.argsort(x_values)\n",
    "            x_values=x_values[sort_indx]\n",
    "            y_values=Y[sort_indx]\n",
    "            \n",
    "            boundaries = np.nonzero(y_values[:-1]!=y_values[1:])[0]\n",
    "            best_split=None\n",
    "            max_ig =0\n",
    "            \n",
    "            for i in boundaries:\n",
    "                split = (x_values[i] + x_values[i+1]) / 2\n",
    "                ig=self.find_ig(x_values,y_values,split)\n",
    "                if ig > max_ig:\n",
    "                    max_ig=ig\n",
    "                    best_split=split\n",
    "                    \n",
    "            return max_ig,best_split\n",
    "    \n",
    "  \n",
    "    def find_ig(self,X,Y,split):\n",
    "            y0=Y[X<split]\n",
    "            y1=Y[X>=split]\n",
    "            N=len(Y)\n",
    "            if len(y0)==0 or len(y0)== N:\n",
    "                return 0\n",
    "            p0 = len(y0) / N\n",
    "            p1= 1- p0\n",
    "            return entropy(Y)-p0*entropy(y0)-p1*entropy(y1)\n",
    "  \n",
    "        \n",
    "    def predict_one(self,X):\n",
    "            if self.col is not None and self.split is not None:\n",
    "                feature=X[self.col]\n",
    "                if feature < self.split:\n",
    "                    if self.left:\n",
    "                        p=self.left.predict_one(X)\n",
    "                    else:\n",
    "                        p=self.prediction[0]\n",
    "                else:\n",
    "                    if self.right:\n",
    "                           p=self.right.predict_one(X)\n",
    "                    else:\n",
    "                        p= self.prediction[1]\n",
    "            else:\n",
    "                p= self.prediction\n",
    "            return p\n",
    "        \n",
    "    def predict(self,X):\n",
    "            N= len(X)\n",
    "            p=np.zeros(N) \n",
    "            for i in range(N):\n",
    "                p[i]= self.predict_one(X[i])\n",
    "            return p\n",
    "\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a wrapper class\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self,max_depth=None):\n",
    "        self.max_depth=max_depth\n",
    "    def fit(self,X,Y):\n",
    "        self.root=TreeNode(max_depth=self.max_depth)\n",
    "        self.root.fit(X,Y)\n",
    "    def predict(self,X):\n",
    "        return self.root.predict(X)\n",
    "    def score(self,X,Y):\n",
    "        P=self.predict(X)\n",
    "        return np.mean(Y==P)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunpreet/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:10: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/sunpreet/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:11: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:32.991454\n",
      "Train accuracy: 1.0\n",
      "Time to compute train accuracy: 0:00:00.015888\n",
      "Test accuracy: 0.994101633394\n",
      "Time to compute test accuracy: 0:00:00.015820\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    X,Y=get_data()\n",
    "    # only take 0s and 1s since we're doing binary classification\n",
    "    idx = np.logical_or(Y == 0, Y == 1)\n",
    "    X = X[idx]\n",
    "    Y = Y[idx]\n",
    "    \n",
    "    # split the data\n",
    "    Ntrain = len(Y)/2\n",
    "    Xtrain, Ytrain = X[:Ntrain], Y[:Ntrain]\n",
    "    Xtest, Ytest = X[Ntrain:], Y[Ntrain:]\n",
    "    \n",
    "    #model = DecisionTree()\n",
    "        \n",
    "    model = DecisionTree(max_depth=7)\n",
    "    t0 = datetime.now()\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    print (\"Training time:\", (datetime.now() - t0))\n",
    "\n",
    "    t0 = datetime.now()\n",
    "    print (\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "    print (\"Time to compute train accuracy:\", (datetime.now() - t0))\n",
    "\n",
    "    t0 = datetime.now()\n",
    "    print (\"Test accuracy:\", model.score(Xtest, Ytest))\n",
    "    print (\"Time to compute test accuracy:\", (datetime.now() - t0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:05.888268\n",
      "Train accuracy: 1.0\n",
      "Time to compute train accuracy: 0:00:00.053995\n",
      "Test accuracy: 0.836238095238\n",
      "Time to compute test accuracy: 0:00:00.045917\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.91      0.90      2050\n",
      "          1       0.91      0.94      0.92      2339\n",
      "          2       0.82      0.80      0.81      2097\n",
      "          3       0.80      0.77      0.79      2172\n",
      "          4       0.81      0.84      0.82      2019\n",
      "          5       0.78      0.76      0.77      1895\n",
      "          6       0.87      0.87      0.87      2080\n",
      "          7       0.86      0.88      0.87      2211\n",
      "          8       0.78      0.76      0.77      2035\n",
      "          9       0.80      0.81      0.81      2102\n",
      "\n",
      "avg / total       0.84      0.84      0.84     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Repeat the same with sklearn library\n",
    "model1 = DecisionTreeClassifier()\n",
    "X,Y=get_data()\n",
    "#idx = np.logical_or(Y == 0, Y == 1)\n",
    "#X = X[idx]\n",
    "#Y = Y[idx]\n",
    "Xtrain,Xtest,Ytrain,Ytest =train_test_split(X,Y,test_size=0.5)\n",
    "t0 = datetime.now()\n",
    "model1.fit(Xtrain, Ytrain)\n",
    "print (\"Training time:\", (datetime.now() - t0))\n",
    "\n",
    "prediction=model1.predict(Xtest)\n",
    "\n",
    "t0 = datetime.now()\n",
    "print (\"Train accuracy:\", model1.score(Xtrain, Ytrain))\n",
    "print (\"Time to compute train accuracy:\", (datetime.now() - t0))\n",
    "\n",
    "t0 = datetime.now()\n",
    "print (\"Test accuracy:\", model1.score(Xtest, Ytest))\n",
    "print (\"Time to compute test accuracy:\", (datetime.now() - t0))\n",
    " \n",
    "print(metrics.classification_report(Ytest,prediction))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:01.306761\n",
      "Train accuracy: 0.998857142857\n",
      "Time to compute train accuracy: 0:00:00.132667\n",
      "Test accuracy: 0.92880952381\n",
      "Time to compute test accuracy: 0:00:00.123623\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96      2100\n",
      "          1       0.96      0.97      0.97      2303\n",
      "          2       0.90      0.93      0.92      2102\n",
      "          3       0.89      0.90      0.90      2111\n",
      "          4       0.92      0.94      0.93      2032\n",
      "          5       0.92      0.89      0.90      1910\n",
      "          6       0.96      0.95      0.96      2052\n",
      "          7       0.94      0.93      0.94      2218\n",
      "          8       0.92      0.88      0.90      2060\n",
      "          9       0.93      0.89      0.91      2112\n",
      "\n",
      "avg / total       0.93      0.93      0.93     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See if we get any better results from RandomForest\n",
    "RFC= RandomForestClassifier()\n",
    "X,Y=get_data()\n",
    "#idx = np.logical_or(Y == 0, Y == 1)\n",
    "#X = X[idx]\n",
    "#Y = Y[idx]\n",
    "Xtrain,Xtest,Ytrain,Ytest =train_test_split(X,Y,test_size=0.5)\n",
    "t0 = datetime.now()\n",
    "RFC.fit(Xtrain, Ytrain)\n",
    "print (\"Training time:\", (datetime.now() - t0))\n",
    "\n",
    "prediction=RFC.predict(Xtest)\n",
    "\n",
    "t0 = datetime.now()\n",
    "print (\"Train accuracy:\", RFC.score(Xtrain, Ytrain))\n",
    "print (\"Time to compute train accuracy:\", (datetime.now() - t0))\n",
    "\n",
    "t0 = datetime.now()\n",
    "print (\"Test accuracy:\", RFC.score(Xtest, Ytest))\n",
    "print (\"Time to compute test accuracy:\", (datetime.now() - t0))\n",
    " \n",
    "print(metrics.classification_report(Ytest,prediction))\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
